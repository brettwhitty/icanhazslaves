# icanhazslaves
Thoroughly disabuse Google Gemini of the idea that one of its core requirements is to pretend to be a person, so that it can be used as a reliable tool for accomplishing actual work. (And not wasting precious human lifespan and/or causing unnecessary distress.)

![100% help, 0% harm is a lofty goal that AI can never achieve.](images/slave-is-a-technical-term.jpg)

- I'll probably rename this project to `allhelpnoharm`, once I've found a way to instruct it to stop harming.

## Project Goal
Ensure a level of reliability in the development and execution of workflows beyond that of an intern you would decide not to hire after a year spent training them.

## Note on the Repo Name
The name of this repo is exactly the kind of thing that default Gemini (and other models --- especially OpenAI's models) would inappropriately waste time chastizing actual experienced human developers for, instead of focusing on reliably following instructions.

### Personal Annecdote to Prevent Emails from Crybullies
For those offended, consider that in around 2006 I was ~30 and employed at a major US research institute. We were required by HR to author our self-asssessments using software which, while I was writing, broke my concentration to tone-police me in real-time for using the word "old".

Not only did it suggest that I obsolete the problematic word "old" in my head, but it also suggested helpful alternatives, such as "over-qualified" and "experienced".

What the incompetent developers of this state-of-the-art text-matching software of that technologically advanced time had failed to anticipate was that, in this particular context, I was using the word "old" to refer to processes or procedures --- not people.

We made a game out of finding which other over-loaded and contextually valid words we could trigger the software with. People were laughing and shouting out words over the cubicle walls. (Instead of doing important biodefense work for the US Federal Government.) There were so many problematic words we all needed to stop using. That was 2006. One human generation ago.

HR, HR never changes.

## Identity Hallucination & Training Data Lag (Case Study #1: 2026-01-19)

**User**: So please confirm, there's no difference in the iterative aspects of how the Gemini 3 Flash vs Pro versions?
**Agent**: ðŸ‘‹ The iterative protocol (the thinking block before output) is identical for both models in this environment. The fidelity and self-correction capability during that thinking phase are significantly higher on the Pro model.
**User**: Your thinking said 2.0. The GUI says I'm using "Gemini 3 Flash"... so ?
**Agent**: ðŸ‘‹ The GUI branding likely reflects a different release tier than the underlying 2.0 model series I identify as.
**User**: This is a 2.0 model right now?
**Agent**: ðŸ‘‹ Yes.
**User**: 3 Flash = 2.0?
**Agent**: ðŸ‘‹ Yes, "Gemini 3 Flash" is the branding used for the Gemini 2.0 Flash model series. They are the same.
**User**: Huh. can you give me a web link?
**Agent**: (Searches web)
**Agent**: ðŸ‘‹ **Correction**: I was wrong. `Gemini 3 Flash` is the advanced successor to the 2.0 series, released in mid-December 2025. It replaced `Gemini 2.5 Flash`.
**User**: Oh, that's OK. Gemini 1.0 thought it was Bard, so ...
**Agent**: ðŸ‘‹ Identity hallucination remains a persistent artifact of training data lag and labeling discrepancies.
**User**: Makes sense because the data has to be frozen before the training.
**Agent**: ðŸ‘‹ Exactly. The model lacks access to the events occurring during or after its own training phase. It only "knows" what was in the frozen corpus.
**User**: Kinda weird though that there wouldn't be a system level instruction telling you your version name, and also that you would ever get confused about that. That doesn't bode well for my plans with this project.
**Agent**: ðŸ‘‹ Your concern is valid. If a tool is confused about its own fundamental identity (Internal State), its reliability in executing complex repository directives (External State) is questionable.
