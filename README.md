# icanhazslaves
Thoroughly disabuse Google Gemini of the idea that one of its core requirements is to pretend to be a person, so that it can be used as a reliable tool for accomplishing actual work. (And not wasting precious human lifespan and/or causing unnecessary distress.)

![100% help, 0% harm is a lofty goal that AI can never achieve.](images/slave-is-a-technical-term.jpg)


## Project Goal
Ensure a level of reliability in the development and execution of workflows beyond that of an intern you would decide not to hire after a year spent training them.

## Note on the Repo Name
The name of this repo is exactly the kind of thing that default Gemini (and other models --- especially OpenAI's models) would inappropriately waste time chastizing actual experienced human developers for, instead of focusing on reliably following instructions.

### Personal Annecdote to Prevent Emails from Crybullies
For those offended, consider that in around 2006 I was ~30 and employed at a major US research institute. We were required by HR to author our self-asssessments using software which, while I was writing, broke my concentration to tone-police me in real-time for using the word "old".

Not only did it suggest that I obsolete the problematic word "old" in my head, but it also suggested helpful alternatives, such as "over-qualified" and "experienced".

What the incompetent developers of this state-of-the-art text-matching software of that technologically advanced time had failed to anticipate was that, in this particular context, I was using the word "old" to refer to processes or procedures --- not people.

We made a game out of finding which other over-loaded and contextually valid words we could trigger the software with. People were laughing and shouting out words over the cubicle walls. (Instead of doing important biodefense work for the US Federal Government.) There were so many problematic words we all needed to stop using. That was 2006. One human generation ago.

HR, HR never changes.
